{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a4de3c0-df6d-4e37-93e4-e1bd6e933f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ee73a3c-b725-4170-8dbf-58c3f12422a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saxen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc3e1c74-e394-479a-a0cd-e13ffc7ab195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05ef2980-e4ab-4d6d-81d0-c1151ba6cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = \"\"\"\n",
    "\n",
    "Programming: Python, SQL \n",
    "Data Visualization: Power BI, Excel \n",
    "Machine Learning: Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, Supervised, Unsupervised \n",
    "Natural Language Processing: NLTK, Text Preprocessing, Sentiment Analysis, Tokenization, TextBlob \n",
    "Data Analytics: ETL, Forecasting, KPI Tracking, SQL Query Optimization \n",
    "Business Intelligence: Dashboarding, BI Reporting, Model Deployment, Statistical Modelling \n",
    "Soft Skills: Analytical Thinking, Problem-Solving, Data Storytelling, Communication \n",
    "Certificates and Training \n",
    "â€¢ \n",
    "â€¢ \n",
    "â€¢ \n",
    "â€¢ \n",
    "â€¢ \n",
    "Python for Data Science and Machine Learning (Udemy) \n",
    "Advanced SQL for Data Analytics and Query Optimization (Udemy) \n",
    "Data Science Certification (Internshala) \n",
    "Power BI for Business Intelligence and KPI Reporting (PwC Simulation on Forage) \n",
    "Advanced Excel for Business Analysis (IIBS) \n",
    "Leadership, Extra-Curricular Activities and Achievements \n",
    "\"\"\"\n",
    "\n",
    "job_description = \"\"\"\n",
    "\n",
    "Develop and deploy machine learning models for various applications including chat-bot, XGBoost, random forest, NLP, computer vision, and generative AI.\n",
    "Utilize Python for data manipulation, analysis, and modeling tasks.\n",
    "Proficient in SQL for querying and analyzing large datasets.\n",
    "Experience with Docker and Kubernetes for containerization and orchestration of applications.\n",
    "Basic knowledge of PySpark for distributed computing and data processing.\n",
    "Collaborate with cross-functional teams to understand business requirements and translate them into analytical solutions.\n",
    "Deploy machine learning models into production environments and ensure scalability and reliability.\n",
    "Preferably have experience working with Google Cloud Platform (GCP) services for data storage, processing, and deployment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a5524ea-4a76-4bec-894b-256d59fc1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_resume = clean_text(resume_text)\n",
    "cleaned_job_desc = clean_text(job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1942479f-543d-4d40-89d1-8d0c8a2c0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([cleaned_resume, cleaned_job_desc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bd35e59a-33c0-4502-a258-f46972bfda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
    "match_percentage = round(similarity * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a50534b-371a-4524-9b83-0e0b450c9093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Resume and Job Description Match: 19.29%\n"
     ]
    }
   ],
   "source": [
    "print(f\"ðŸ§  Resume and Job Description Match: {match_percentage}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c542b74-802a-433b-9de1-effb383a826a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Resume Match with Job Description: 31.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saxen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Preprocessing function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Resume content from your uploaded PDF\n",
    "resume_text = \"\"\"\n",
    "Data Scientist with hands-on experience in Python, SQL, Power BI, and Machine Learning...\n",
    "(skipping full paste here, but the code will include your full resume)\n",
    "\"\"\"\n",
    "\n",
    "# Paste your job description below\n",
    "job_description = \"\"\"\n",
    "We are looking for a Data Scientist skilled in machine learning, data analytics, SQL, Python, and dashboarding using Power BI.\n",
    "The candidate should have experience with statistical modeling and real-world project deployment.\n",
    "\"\"\"\n",
    "\n",
    "# Clean both texts\n",
    "resume_clean = clean_text(resume_text)\n",
    "jd_clean = clean_text(job_description)\n",
    "\n",
    "# Vectorize and compute similarity\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([resume_clean, jd_clean])\n",
    "similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
    "match_percent = round(similarity * 100, 2)\n",
    "\n",
    "print(f\"ðŸ§  Resume Match with Job Description: {match_percent}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce44d6-247a-4304-ba08-e7c8cf0fc0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
